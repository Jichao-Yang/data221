{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Homework 1\n",
    "author: Jichao Yang\n",
    "format: \n",
    "    pdf:\n",
    "        documentclass: article\n",
    "        papersize: letter\n",
    "        geometry:\n",
    "            - top = 1in\n",
    "            - bottom = 1in\n",
    "            - left = 1in\n",
    "            - right = 1in\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Unless specifically mentioned, the sum and product operators below all range within set $\\{x_1, \\cdots, x_8\\}$.\\\n",
    "(a) Likelihood function can be found as follow:\n",
    "$$\n",
    "L = \\prod P(X = x_i)= \\prod e^{-\\lambda} \\frac{\\lambda^{x_i}}{x_i!} = e^{-8\\lambda} \\cdot \\frac{\\lambda^{\\sum x_i}}{\\prod x_n!}\n",
    "$$\n",
    "(b) The log likelihood can be found as follow:\n",
    "$$\n",
    "{\\mathcal L} = log(L) = -8\\lambda + log(\\lambda)\\cdot \\sum x_i - \\sum log(x_i!)\n",
    "$$\n",
    "(c) Function ${\\mathcal L}(\\lambda) = c_0 + c_1\\cdot \\lambda + c_2\\cdot ln(\\lambda)$ is the sum of convex functions, hence ${\\mathcal L}$ is convex. Therefore ${\\mathcal L}$ reaches its maximum if and only if its derivative is 0. Solving this equation we have:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d}{d\\lambda}{\\mathcal L} &= -8 + \\frac{1}{\\lambda} \\cdot \\sum x_i = 0\\\\\n",
    "\\lambda &= \\frac{1}{8}\\sum{x_i}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "(a) The estimation for $\\lambda$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimation for lambda is 26.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = np.array([32,25,28,22,31,34,23,17])\n",
    "l = sum(counts) / 8\n",
    "\n",
    "print('The estimation for lambda is {}'.format(np.round(l,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Below is the function that calculates the negative log likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "def nll(l, counts):\n",
    "    '''\n",
    "    Returns the negative log likelihood of given observation counts and rate\n",
    "    parameter l.\n",
    "    '''\n",
    "    return 8*l - np.log(l)*np.sum(counts) + np.sum(np.log(factorial(counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) We use the Scipy optimizer to find the minimum negative loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimator found using scipy is 26.49999\n",
      "The estimator calculated in Problem 1 is 26.5\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Using initial guess 20 which is decently close to l\n",
    "l_hat = minimize(nll, [20], args=counts).x[0]\n",
    "# Does the analytic solution agree with the optimization?\n",
    "assert np.isclose(l,l_hat)\n",
    "\n",
    "print('The estimator found using scipy is {}'.format(np.round(l_hat, 5)))\n",
    "print('The estimator calculated in Problem 1 is {}'.format(np.round(l, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated estimator is reasonably close to the optimized estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "(a) Denote the value of the two dice $d_1, d_2$. The conditional probability can be calculated with:\n",
    "$$\n",
    "P(d_1=4 | d_1+d_2=7) = \\frac{P(d_1=4 \\cap d_1+d_2=7)}{P(d_1+d_2=7)} = \\frac{(1/6)^2}{(1/6)^2 \\cdot 6} = \\frac{1}{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Denote families owning dogs $D$ and cats $C$. The conditional probability can be calculated with:\n",
    "$$\n",
    "P(D|C) = \\frac{P(D \\cap C )}{P(C)} = \\frac{1/3\\cdot 0.6}{0.4} = \\frac{1}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "(a) Denote the ordered set of throws $D = \\{5,3,9,3,8,4,7\\}$. We first calculate a few useful values for solving the problem:\n",
    "$$\n",
    "P(D|A) = \\frac{3\\cdot 3\\cdot 2}{20^7} = \\frac{18}{20^7};\\quad P(D|B) = \\frac{2^6}{20^7} = \\frac{64}{20^7};\\quad P(D|E) = \\frac{2^7}{20^7} = \\frac{128}{20^7}\n",
    "$$\n",
    "$$\n",
    "P(D) = P(D|A)\\cdot P(A) + P(D|B)\\cdot P(B) + P(D|E)\\cdot P(E) = \\frac{1}{3}\\cdot \\frac{210}{20^7}\n",
    "$$\n",
    "Using the Bayes equation we have the following:\n",
    "$$\n",
    "P(A|D) = \\frac{P(D|A)\\cdot P(A)}{P(D)} = \\frac{18}{210};\\quad P(B|D) = \\frac{64}{210};\\quad P(E|D) = \\frac{128}{210}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Take calculations done in step (a) as the prior. Denote $D'$ as the final die roll of 10. We can calculate the following:\n",
    "$$\n",
    "P(D') = P(D'|A) P(A) + P(D'|B)P(B) + P(D'|E) P(E) = 0\\cdot \\frac{18}{210} + \\frac{1}{20}\\cdot \\frac{64}{210} + \\frac{2}{20}\\cdot \\frac{128}{210} = \\frac{16}{210}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(A|D') = \\frac{P(D'|A)\\cdot P(A)}{P(D')} = \\frac{0\\cdot 18/210}{16/210} = 0;\\quad P(B|D') = \\frac{1}{5};\\quad P(E|D') = \\frac{4}{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) The consequences of A being impossible to roll a 10 is that the posterior probability of A is 0. In other words, the prior probability of A becomes 'distributed' among B and C after the additional roll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Recall that given a set of rolls $D$, there is a established 99:1 confidence between B and E if and only if\n",
    "$$\n",
    "\\frac{P(B|D)}{P(E|D)} \\leq \\frac{1}{99} \\text{ or } \\frac{P(B|D)}{P(E|D)} \\geq \\frac{99}{1}\n",
    "$$\n",
    "Given any prior rolls $D$, we can calculate the current value for $P(B)$ and $P(E)$. For new roll $D'$, the probability can be updated as follow:\n",
    "$$\n",
    "P(B|D') = \\frac{P(D'|B)}{P(D')}\\cdot P(B);\\quad P(E|D') = \\frac{P(D'|E)}{P(D')}\\cdot P(E)\n",
    "$$\n",
    "Hence the quotient can be updated as follow:\n",
    "$$\n",
    "\\frac{P(B|D')}{P(E|D')} = \\frac{P(D'|B)}{P(D'|E)} \\cdot \\frac{P(B)}{P(E)}\n",
    "$$\n",
    "For accuracy of calculation, we define the log confidence as\n",
    "$$\n",
    "{\\mathcal L} = log(\\frac{P(B)}{P(E)})\n",
    "$$\n",
    "Hence the log confidence can be iteratively updated by the following rule\n",
    "$$\n",
    "{\\mathcal L'} = {\\mathcal L} + log(P(D'|B)) - log(P(D'|E))\n",
    "$$\n",
    "until we reach the breaking condition\n",
    "$$\n",
    "{\\mathcal L'} \\leq -log(99) \\text{ or } {\\mathcal L'} \\geq log(99)\n",
    "$$\n",
    "Below is the implementation of the algorithm:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
